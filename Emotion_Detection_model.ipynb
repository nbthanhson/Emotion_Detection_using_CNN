{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Emotion-Detection_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wHghNN7GMqQ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTVPIk75odKZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Load dataset\n",
        "path = '/content/gdrive/MyDrive/Emotion Detection/Data/fer2013.csv'\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "#Split data into training and testing set\n",
        "train_x, train_y, val_x, val_y, test_x, test_y = [], [], [], [], [], []\n",
        "for index, row in df.iterrows():\n",
        "    val = row['pixels'].split(' ')\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "            train_x.append(np.array(val, 'float32'))\n",
        "            train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "            val_x.append(np.array(val, 'float32'))\n",
        "            val_y.append(row['emotion'])\n",
        "        else:\n",
        "            test_x.append(np.array(val, 'float32'))\n",
        "            test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print('Error occured at index: {} and row: {}'.format(index, row))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cvf-TFSzlE5"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "train_x = np.array(train_x, 'float32')\n",
        "train_y = np.array(train_y, 'float32')\n",
        "val_x = np.array(val_x, 'float32')\n",
        "val_y = np.array(val_y, 'float32')\n",
        "test_x = np.array(test_x, 'float32')\n",
        "test_y = np.array(test_y, 'float32')\n",
        "\n",
        "train_y = np_utils.to_categorical(train_y, num_classes = 7)\n",
        "val_y = np_utils.to_categorical(val_y, num_classes = 7)\n",
        "test_y = np_utils.to_categorical(test_y, num_classes = 7)\n",
        "\n",
        "train_x /= 255.0\n",
        "train_x -= 0.5\n",
        "train_x *= 2.0\n",
        "val_x /=255.0\n",
        "val_x -= 0.5\n",
        "val_x *= 2.0\n",
        "test_x /= 255.0\n",
        "test_x -= 0.5\n",
        "test_x *= 2.0\n",
        "\n",
        "train_x = train_x.reshape(train_x.shape[0], 48, 48, 1)\n",
        "val_x = val_x.reshape(val_x.shape[0], 48, 48, 1)\n",
        "test_x = test_x.reshape(test_x.shape[0], 48, 48, 1)\n",
        "\n",
        "val_data = (val_x, val_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiQijp8i9eP-"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Add the first Block\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same', activation = 'relu', input_shape = train_x.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "\n",
        "#Add the second Block\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "\n",
        "#Add the third Block\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "\n",
        "#Add the four Block\n",
        "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'same', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "\n",
        "#Add the Flatten layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#Add the ouput layer\n",
        "model.add(Dense(units = 256, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units = 64, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units = 7, activation = 'softmax'))\n",
        "\n",
        "#Display model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhr9V0jeteHU"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "                        featurewise_center = False, \n",
        "                        featurewise_std_normalization = False,\n",
        "                        rotation_range = 10,\n",
        "                        width_shift_range = 0.1,\n",
        "                        height_shift_range = 0.1,\n",
        "                        zoom_range = 0.1,\n",
        "                        horizontal_flip = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV28cuZ7CiMl"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#Early stop training\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 15, verbose = 1)\n",
        "\n",
        "#Save the best model\n",
        "best_model = ModelCheckpoint(filepath = 'Emotion_Detection_bestmodel.h5', monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
        "\n",
        "#Reduce learning rate\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 10, verbose = 1, min_lr = 0.0001)\n",
        "\n",
        "#Start training\n",
        "model_history = model.fit(\n",
        "                        data_generator.flow(train_x, train_y, batch_size = 128),\n",
        "                        epochs = 100,\n",
        "                        validation_data = val_data,\n",
        "                        callbacks = [early_stopping, best_model, reduce_lr],\n",
        "                        shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlivG6XaES1t"
      },
      "source": [
        "#Load the best model\n",
        "keras.models.load_model(filepath = 'Emotion_Detection_bestmodel.h5')\n",
        "\n",
        "model.evaluate(test_x, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQaNu6HuihJ4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Get training loss and validation loss from model history\n",
        "history_dict = model_history.history\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "#Diplay a chart of training loss and validation loss\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training loss', 'Val loss'], loc='center right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvnSol_merlf"
      },
      "source": [
        "#Get training accuracy and validation loss from model history\n",
        "history_dict = model_history.history\n",
        "accuracy = history_dict['accuracy']\n",
        "val_accuracy = history_dict['val_accuracy']\n",
        "\n",
        "#Diplay a chart of training accuracy and validation accuracy\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy)\n",
        "plt.plot(epochs, val_accuracy)\n",
        "\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training accuracy', 'Val accuracy'], loc='center right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjkoc5eBFlrY"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "#Testing the model on some images\n",
        "categories = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "def prepare(img_data):\n",
        "    img_data = cv2.resize(img_data, (48, 48))\n",
        "    img_data = img_data.astype('float32')\n",
        "    img_data /= 255.0\n",
        "    img_data -= 0.5\n",
        "    img_data *= 2.0\n",
        "    return img_data.reshape(-1, 48, 48, 1)\n",
        "\n",
        "img_text = '/content/gdrive/MyDrive/Emotion Detection/Test/'\n",
        "\n",
        "count = 1\n",
        "for f in os.listdir(img_text):\n",
        "    plt.figure(figsize=(100,100))\n",
        "    plt.subplot(len(os.listdir(img_text)), 1, count)\n",
        "    files = os.path.join(img_text, f)\n",
        "    img = cv2.imread(files)\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
        "    grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(grayImage)\n",
        "    for (x, y, w, h) in faces:\n",
        "        img_face = grayImage[y:y+h, x:x+w]\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
        "        prediction = model.predict([prepare(img_face)])\n",
        "        category = categories[np.argmax(prediction)]\n",
        "        cv2.putText(img, category, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
        "    count += 1\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}